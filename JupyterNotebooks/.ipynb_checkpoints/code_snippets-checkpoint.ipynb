{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Fixing-a-random-seed-to-the-code\" data-toc-modified-id=\"Fixing-a-random-seed-to-the-code-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Fixing a random seed to the code</a></span></li><li><span><a href=\"#Plotting-correlation-matrix-as-a-heat-map\" data-toc-modified-id=\"Plotting-correlation-matrix-as-a-heat-map-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Plotting correlation matrix as a heat map</a></span></li><li><span><a href=\"#Plotting-the-confusion-matrix\" data-toc-modified-id=\"Plotting-the-confusion-matrix-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Plotting the confusion matrix</a></span></li><li><span><a href=\"#Plotting-PR-Curve\" data-toc-modified-id=\"Plotting-PR-Curve-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plotting PR Curve</a></span></li><li><span><a href=\"#Plotting-ROC-Curve\" data-toc-modified-id=\"Plotting-ROC-Curve-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Plotting ROC Curve</a></span></li><li><span><a href=\"#Split-a-dataset-using-random-sampling\" data-toc-modified-id=\"Split-a-dataset-using-random-sampling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Split a dataset using random sampling</a></span></li><li><span><a href=\"#Split-a-dataset-using-random-sampling-and-hashing-technique\" data-toc-modified-id=\"Split-a-dataset-using-random-sampling-and-hashing-technique-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Split a dataset using random sampling and hashing technique</a></span></li><li><span><a href=\"#Split-using-stratified-sampling\" data-toc-modified-id=\"Split-using-stratified-sampling-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Split using stratified sampling</a></span></li><li><span><a href=\"#Build-a-correlation-matrix-using-Pearson's-correlation-coefficient\" data-toc-modified-id=\"Build-a-correlation-matrix-using-Pearson's-correlation-coefficient-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Build a correlation matrix using Pearson's correlation coefficient</a></span></li><li><span><a href=\"#Build-scatter-matrix-of-numerical-attributes\" data-toc-modified-id=\"Build-scatter-matrix-of-numerical-attributes-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Build scatter matrix of numerical attributes</a></span></li><li><span><a href=\"#Imputer\" data-toc-modified-id=\"Imputer-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Imputer</a></span></li><li><span><a href=\"#Modifying-a-text-categorical-column-to-integer-categorical-column\" data-toc-modified-id=\"Modifying-a-text-categorical-column-to-integer-categorical-column-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Modifying a text categorical column to integer categorical column</a></span></li><li><span><a href=\"#Modifying-an-integer-categorical-column-to-one-hot-encoding\" data-toc-modified-id=\"Modifying-an-integer-categorical-column-to-one-hot-encoding-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Modifying an integer categorical column to one hot encoding</a></span></li><li><span><a href=\"#Modifying-a-text-categorical-column-to-onehotencoding\" data-toc-modified-id=\"Modifying-a-text-categorical-column-to-onehotencoding-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Modifying a text categorical column to onehotencoding</a></span></li><li><span><a href=\"#sklearn's-cross-validator\" data-toc-modified-id=\"sklearn's-cross-validator-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>sklearn's cross validator</a></span></li><li><span><a href=\"#Display-cross-validation-scores\" data-toc-modified-id=\"Display-cross-validation-scores-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Display cross validation scores</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing a random seed to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting correlation matrix as a heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faster for datasets with large number of columns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(dataframe.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "plot_confusion_matrix(conf_matrix, classes = list_of_class_names )\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Plotting PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g--\", label = \" Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"center left\")\n",
    "    plt.ylim([0,1.1])\n",
    "\n",
    "plt.figure(figsize=(15,7))    \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#plot precision vs recall\n",
    "plt.plot(recalls, precisions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Plotting ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label = \"classifier_name\"):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label = label)\n",
    "    plt.plot([0,1], [0,1], 'k--', label = \"random_classifier\")\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split a dataset using random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shufled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split a dataset using random sampling and hashing technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    "\n",
    "def split_train_test_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    print(ids)\n",
    "    in_test_set = ids.apply(lambda id_ :test_set_check(id_, test_ratio, hash))\n",
    "    print(in_test_set)\n",
    "    \n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split using stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(df_housing, df_housing[\"income_cat\"]):\n",
    "    strat_train_set = df_housing.loc[train_index]\n",
    "    strat_test_set = df_housing.loc[test_index]\n",
    "    \n",
    "#you can also use StratifiedKFold module with 2 splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Build a correlation matrix using Pearson's correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Build scatter matrix of numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "#build a list of columns you want to visualize\n",
    "scatter_matrix(df[columns_list], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fill Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy = \"Median\")\n",
    "imputer.fit(X_train)\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Handling categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modifying a text categorical column to integer categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_column_encoded, df_column_categories = df_column.factorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modifying an integer categorical column to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = Encoder()\n",
    "df_cat_col_1hot = encoder.fit_transform(df_cat_col.reshape(1,-1))\n",
    "df_cat_col_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modifying a text categorical column to onehotencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import CategoricalEncoder\n",
    "cat_encoder = CategoricalEncoder()\n",
    "df_cat_1hot = cat_encoder.fit_transform(df_cat_column.values.reshape(-1,1))\n",
    "#return type is a sparce matrix\n",
    "cat_encoder = CategoricalEncoder(encoding=\"onehot-dense\")\n",
    "df_cat_1hot = cat_encoder.fit_transform(df_cat_column.values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## sklearn's cross validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#the cross validation method takes a utility function for scoring rather than a cost function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model_instance, training_features, training_label,\n",
    "                        scoring = \"utility_function\", cv=no_of_folds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Display cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_cross_val_scores(scores):\n",
    "    print(\"SCores: \", scores)\n",
    "    print(\"Mean: \",scores.mean())\n",
    "    print(\"Standard Deviation: \",scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_param_= {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Create the object.\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "# Fit the data\n",
    "grid_fit = grid_obj.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = grid_search.cv_results_\n",
    "for mean_valid_score, mean_tr_score, params in zip(res[\"mean_test_score\"],res['mean_train_score'],res[\"params\"]):\n",
    "    print(np.sqrt(-mean_valid_score),np.sqrt(-mean_tr_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(-grid_search.best_score_)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#doing a cross validation over the best estimator\n",
    "svm_reg = grid_search.best_estimator_\n",
    "scores = cross_val_score(svm_reg, X_train_prepared, y_train, cv=5, scoring = \"neg_mean_squared_error\")\n",
    "svm_reg_scores = np.sqrt(-scores)\n",
    "print(\"rmse\",svm_reg_scores.mean())\n",
    "svm_reg_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# It is good to randomize the data before drawing Learning Curves\n",
    "def randomize(X, Y):\n",
    "    permutation = np.random.permutation(Y.shape[0])\n",
    "    X2 = X[permutation,:]\n",
    "    Y2 = Y[permutation]\n",
    "    return X2, Y2\n",
    "\n",
    "X2, y2 = randomize(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#IMPROVE IT https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def draw_learning_curves(X, y, estimator, num_trainings):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X2, y2, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, num_trainings))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    plt.plot(train_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(test_scores_mean, 'o-', color=\"y\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#function to draw a learning curve for RMSE -- To be improved\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def draw_learning_curves(X, y, estimator, num_trainings):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=10, n_jobs=1, scoring='neg_mean_squared_error',shuffle = True,train_sizes=np.linspace(.1, 1.0, num_trainings))\n",
    "\n",
    "    train_scores_mean = np.sqrt(np.mean(-train_scores, axis=1))\n",
    "    train_scores_std = np.sqrt(np.std(-train_scores, axis=1))\n",
    "    test_scores_mean = np.sqrt(np.mean(-test_scores, axis=1))\n",
    "    test_scores_std = np.sqrt(np.std(-test_scores, axis=1))\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    #plt.ylim(-70,0)\n",
    "\n",
    "    plt.plot(train_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(test_scores_mean, 'o-', color=\"y\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# After you get your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit the new model.\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the new model.\n",
    "best_train_predictions = best_clf.predict(X_train)\n",
    "best_test_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Calculate the f1_score of the new model.\n",
    "print('The training F1 Score is', f1_score(best_train_predictions, y_train))\n",
    "print('The testing F1 Score is', f1_score(best_test_predictions, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
