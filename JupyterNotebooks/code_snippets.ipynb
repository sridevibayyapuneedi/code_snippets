{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Split-a-dataset-using-random-sampling\" data-toc-modified-id=\"Split-a-dataset-using-random-sampling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Split a dataset using random sampling</a></span></li><li><span><a href=\"#Split-a-dataset-using-random-sampling-and-hashing-technique\" data-toc-modified-id=\"Split-a-dataset-using-random-sampling-and-hashing-technique-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Split a dataset using random sampling and hashing technique</a></span></li><li><span><a href=\"#Split-using-stratified-sampling\" data-toc-modified-id=\"Split-using-stratified-sampling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Split using stratified sampling</a></span></li><li><span><a href=\"#Build-a-correlation-matrix-using-Pearson's-correlation-coefficient\" data-toc-modified-id=\"Build-a-correlation-matrix-using-Pearson's-correlation-coefficient-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build a correlation matrix using Pearson's correlation coefficient</a></span></li><li><span><a href=\"#Build-scatter-matrix-of-numerical-attributes\" data-toc-modified-id=\"Build-scatter-matrix-of-numerical-attributes-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Build scatter matrix of numerical attributes</a></span></li><li><span><a href=\"#Imputer\" data-toc-modified-id=\"Imputer-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Imputer</a></span></li><li><span><a href=\"#Modifying-a-text-categorical-column-to-integer-categorical-column\" data-toc-modified-id=\"Modifying-a-text-categorical-column-to-integer-categorical-column-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Modifying a text categorical column to integer categorical column</a></span></li><li><span><a href=\"#Modifying-an-integer-categorical-column-to-one-hot-encoding\" data-toc-modified-id=\"Modifying-an-integer-categorical-column-to-one-hot-encoding-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Modifying an integer categorical column to one hot encoding</a></span></li><li><span><a href=\"#Modifying-a-text-categorical-column-to-onehotencoding\" data-toc-modified-id=\"Modifying-a-text-categorical-column-to-onehotencoding-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Modifying a text categorical column to onehotencoding</a></span></li><li><span><a href=\"#sklearn's-cross-validator\" data-toc-modified-id=\"sklearn's-cross-validator-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>sklearn's cross validator</a></span></li><li><span><a href=\"#Display-cross-validation-scores\" data-toc-modified-id=\"Display-cross-validation-scores-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Display cross validation scores</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split a dataset using random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shufled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split a dataset using random sampling and hashing technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    "\n",
    "def split_train_test_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    print(ids)\n",
    "    in_test_set = ids.apply(lambda id_ :test_set_check(id_, test_ratio, hash))\n",
    "    print(in_test_set)\n",
    "    \n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split using stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(df_housing, df_housing[\"income_cat\"]):\n",
    "    strat_train_set = df_housing.loc[train_index]\n",
    "    strat_test_set = df_housing.loc[test_index]\n",
    "    \n",
    "#you can also use StratifiedKFold module with 2 splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Build a correlation matrix using Pearson's correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Build scatter matrix of numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "#build a list of columns you want to visualize\n",
    "scatter_matrix(df[columns_list], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fill Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy = \"Median\")\n",
    "imputer.fit(X_train)\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Handling categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modifying a text categorical column to integer categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_column_encoded, df_column_categories = df_column.factorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modifying an integer categorical column to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = Encoder()\n",
    "df_cat_col_1hot = encoder.fit_transform(df_cat_col.reshape(1,-1))\n",
    "df_cat_col_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modifying a text categorical column to onehotencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import CategoricalEncoder\n",
    "cat_encoder = CategoricalEncoder()\n",
    "df_cat_1hot = cat_encoder.fit_transform(df_cat_column.values.reshape(-1,1))\n",
    "#return type is a sparce matrix\n",
    "cat_encoder = CategoricalEncoder(encoding=\"onehot-dense\")\n",
    "df_cat_1hot = cat_encoder.fit_transform(df_cat_column.values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn's cross validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the cross validation method takes a utility function for scoring rather than a cost function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model_instance, training_features, training_label,\n",
    "                        scoring = \"utility_function\", cv=no_of_folds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cross_val_scores(scores):\n",
    "    print(\"SCores: \", scores)\n",
    "    print(\"Mean: \",scores.mean())\n",
    "    print(\"Standard Deviation: \",scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_param_= {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Create the object.\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "# Fit the data\n",
    "grid_fit = grid_obj.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = grid_search.cv_results_\n",
    "for mean_valid_score, mean_tr_score, params in zip(res[\"mean_test_score\"],res['mean_train_score'],res[\"params\"]):\n",
    "    print(np.sqrt(-mean_valid_score),np.sqrt(-mean_tr_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(-grid_search.best_score_)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing a cross validation over the best estimator\n",
    "svm_reg = grid_search.best_estimator_\n",
    "scores = cross_val_score(svm_reg, X_train_prepared, y_train, cv=5, scoring = \"neg_mean_squared_error\")\n",
    "svm_reg_scores = np.sqrt(-scores)\n",
    "print(\"rmse\",svm_reg_scores.mean())\n",
    "svm_reg_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is good to randomize the data before drawing Learning Curves\n",
    "def randomize(X, Y):\n",
    "    permutation = np.random.permutation(Y.shape[0])\n",
    "    X2 = X[permutation,:]\n",
    "    Y2 = Y[permutation]\n",
    "    return X2, Y2\n",
    "\n",
    "X2, y2 = randomize(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPROVE IT https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def draw_learning_curves(X, y, estimator, num_trainings):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X2, y2, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, num_trainings))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    plt.plot(train_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(test_scores_mean, 'o-', color=\"y\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
